{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Text Summarization with Pyspark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "from pyspark.sql import Row\n",
    "\n",
    "all_wikipedia_files = sc.wholeTextFiles(\"s3://strata-demo-data/nlp_data/*(Clean Splits).txt\")\n",
    "wikipage_rdd_list = []\n",
    "#for i in range(30):\n",
    "for i in range(1):\n",
    "    wikipage_rdd = all_wikipedia_files\\\n",
    "        .filter(lambda element: element[0].endswith('_' + str(i) + '(Clean Splits).txt'))\\\n",
    "        .values()\\\n",
    "        .flatMap(lambda text_string: text_string.split(\"---END.OF.DOCUMENT---\"))\\\n",
    "        .map(lambda text_string: text_string.strip(\"\\r\\n\").replace(\"\\r\\n\", \"\\n\"))\n",
    "  \n",
    "    wikipage_rdd.cache()\n",
    "    # Change from rdd of strings to rdd of rows\n",
    "    wikipage_rdd = wikipage_rdd.map(lambda element: Row(Body=element))\n",
    "    wikipage_rdd_list.append(wikipage_rdd)\n",
    "    \n",
    "combined_wikipage_rdd = sc.union(wikipage_rdd_list)\n",
    "\n",
    "# Convert from rdd to dataframe\n",
    "combined_wikipage_dataframe = spark.createDataFrame(combined_wikipage_rdd).repartition(256)\n",
    "combined_wikipage_dataframe.head()\n",
    "#combined_wikipage_dataframe.write.format(\"csv\")\\\n",
    "#    .option(\"header\", \"true\")\\\n",
    "#    .mode(\"append\")\\\n",
    "#    .save(\"s3://strata-demo-data/nlp_data/Post_Processed_Wikipedia_Corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "import re\n",
    "from pyspark.sql.functions import udf\n",
    "# Extract Wikipedia page title into new column\n",
    "def extract_wikipage_title(wikipage_body):\n",
    "    matched_item = re.match(\"(.*)\\\\n\", wikipage_body)\n",
    "    return matched_item.group(1) if matched_item else \"N/A\"\n",
    "\n",
    "# Remove Wikipedia page title from item body\n",
    "def remove_title_from_item_body(wikipage_body):\n",
    "    matched_item = re.match(\"(.*)\\\\n\", wikipage_body)\n",
    "    return wikipage_body[matched_item.end(1):].strip(\"\\n\") if matched_item else wikipage_body\n",
    "    \n",
    "    \n",
    "extract_wikipage_title_udf = udf(extract_wikipage_title)\n",
    "remove_title_from_item_body_udf = udf(remove_title_from_item_body)\n",
    "\n",
    "combined_wikipage_dataframe = combined_wikipage_dataframe\\\n",
    "    .filter(combined_wikipage_dataframe.Body != \"\")\\\n",
    "    .withColumn(\"Title\", extract_wikipage_title_udf(combined_wikipage_dataframe.Body))\\\n",
    "    .select(\"Title\", \"Body\")\n",
    "\n",
    "combined_wikipage_dataframe = combined_wikipage_dataframe\\\n",
    "    .withColumn(\"Body\", remove_title_from_item_body_udf(combined_wikipage_dataframe.Body))\n",
    "    \n",
    "combined_wikipage_dataframe.cache()\n",
    "combined_wikipage_dataframe.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from gensim.summarization.summarizer import summarize\n",
    "\n",
    "# Summarize \"Body\" column and assign to \"Summary\"\n",
    "def summarize_body(body):\n",
    "    try:\n",
    "        text_summary = summarize(body)\n",
    "    except ValueError:\n",
    "        text_summary = body\n",
    "    return text_summary\n",
    "    \n",
    "# summarize_body_udf = udf(lambda body: summarize(body), StringType()) \n",
    "summarize_body_udf = udf(summarize_body, StringType())\n",
    "\n",
    "combined_wikipage_dataframe = combined_wikipage_dataframe\\\n",
    "    .withColumn(\"Summary\", summarize_body_udf(combined_wikipage_dataframe.Body))\n",
    "\n",
    "combined_wikipage_dataframe.cache()\n",
    "examples = combined_wikipage_dataframe.head(3)\n",
    "for example in examples:\n",
    "    print(\"Title:\")\n",
    "    print(example.Title)\n",
    "    print(\"Body:\")\n",
    "    print(example.Body)\n",
    "    print(\"Summary:\")\n",
    "    print(example.Summary)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "combined_wikipage_dataframe.write.parquet(\"s3://strata-demo-data/nlp_data/wikipage_summarization.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2.0.0 - Scala 2.11",
   "language": "scala",
   "name": "spark2-scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
